{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DrpK6lIWrhi"
      },
      "source": [
        "# Deep Learning - RNN Sentiment Analysis\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide an example that shows the implementation of a simple RNN for sentiment analysis in PyTorch.\n",
        "\n",
        "Copyright (c) 2022 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since [TorchData](https://github.com/pytorch/data) depends on nightly builds of PyTorch, to avoid any versioning issues, we will be using an earlier version of [TorchText](https://pytorch.org/text/stable/index.html), but outside the Google Colab environment, you can use the newer version of TorchText, which is clear and much better and has removed a lot of unnecessary abstraction.\n",
        " "
      ],
      "metadata": {
        "id": "y8-07GGp-fMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U torch==1.8.0 torchtext==0.9.0\n",
        "!pip install -U torchtext==0.11.0\n",
        "\n",
        "# Reload environment\n",
        "exit()\n",
        "\n",
        "print('done!')"
      ],
      "metadata": {
        "id": "UzhVGwSJ_mhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going take advantage of the power of RNNs to build a model that is capable of detecting sentiment (i.e., whether a sentence is positive or negative) using PyTorch and TorchText. This will be done on movie reviews, using the [IMDb dataset](http://ai.stanford.edu/~amaas/data/sentiment/)."
      ],
      "metadata": {
        "id": "9x85uyaEzXw4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-exrFDujXlUG"
      },
      "source": [
        "Let's start by importing what we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Xgr3ZNXmQx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "\n",
        "print(f'torch version: {torch.__version__}')\n",
        "print(f'torchtext version: {torchtext.__version__}')\n",
        "\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Device is {device}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZr-PApBcN4Y"
      },
      "source": [
        "In the earlier version of the TorchText we are using, `Field` is one of the main concepts, which defines how the data should be processed. In the sentiment classification task we are addressing here, the data consists of string of the review (the main body of the text) and the sentiment, either \"pos\" or \"neg\" (the label).\n",
        "\n",
        "The parameters of a `Field` specify how the data should be processed. Here, we use the `TEXT` field to define how the text is processed, and the `LABEL` field handles the label.\n",
        "\n",
        "*N.B.* None of this faffing is needed in the new version of TorchText."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6AZQ9Kq_1hj"
      },
      "source": [
        "Our `TEXT` has the argument `tokenize='spacy'` as an argument. This defines that the tokenisation method, which separates our text string into \"tokens\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbTxY01eY0Aq"
      },
      "outputs": [],
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "print('done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5UnQLwJZW6O"
      },
      "source": [
        "Now, we can get the dataset, which is already built into TorchText. The following command will download the IMDB dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVqAtMBuw8LW"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "print(f'\\nThere are {len(train_data)} data points in the training set!')\n",
        "print(f'There are {len(test_data)} data points in the testing set!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt8tSeQcy_jZ"
      },
      "source": [
        "Let's check one of the data samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pou-TRizzZXP"
      },
      "outputs": [],
      "source": [
        "print(vars(train_data.examples[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBDngw8EueCv"
      },
      "source": [
        "Now is the time to build a vocabulary with a one-hot vector for each token. To keep things small and efficient, we are going to keep the vocabulary at 10,000 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccMuktrKukIj"
      },
      "outputs": [],
      "source": [
        "MAX_VOCAB_SIZE = 10_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"LABEL vocabulary: {len(LABEL.vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the extra two tokens we see there are `<unk>` and `<pad>` tokens."
      ],
      "metadata": {
        "id": "lB1Vmy4OHYyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to create iterators for our data. Let's use a `BucketIterator` which returns a batch of examples where each example is of a similar length, minimizing the amount of padding per example.\n",
        "\n",
        "Once again, note that with the newer versions of torchtext, life is a lot easier."
      ],
      "metadata": {
        "id": "98c2vQgaJAyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, test_data), \n",
        "    batch_size = batch_size,\n",
        "    device = device)\n",
        "\n",
        "print('Data iterators have been created!')"
      ],
      "metadata": {
        "id": "HCm-JMNCJlzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will create our optimiser and our network, a very simple architecture made up of an embedding layer, an RNN layer and a linear layer:"
      ],
      "metadata": {
        "id": "5Usd9bZHKuQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build architecture:\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "      \n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim)  \n",
        "    self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "      \n",
        "  def forward(self, text):\n",
        "\n",
        "    embedded = self.embedding(text)\n",
        "    output, hidden = self.rnn(embedded)\n",
        "    \n",
        "    assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "    \n",
        "    return self.fc(hidden.squeeze(0))\n",
        "\n",
        "# a few parameters to set for our model:\n",
        "input_dim = len(TEXT.vocab)\n",
        "embed_dim = 100\n",
        "hidden_dim = 256\n",
        "output_dim = 1\n",
        "\n",
        "model = RNN(input_dim, embed_dim, hidden_dim, output_dim)\n",
        "model = model.to(device)\n",
        "\n",
        "print(model)\n",
        "print('Model has been created!')\n",
        "print(f'Model has {sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters!')\n",
        "\n",
        "# create the optimiser:\n",
        "optimiser = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "# loss function:\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "I3o9_dMyK3qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to keep track of how our model performs we need to calculate the accuracy of our predictions. This helper function will help us computer accuracy:"
      ],
      "metadata": {
        "id": "K4Q2w3CfRk4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy:\n",
        "def binary_accuracy(preds, y):\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "qu5l408MR5JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now the main training loop:"
      ],
      "metadata": {
        "id": "ogjYCWEZPS85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "# main loop:\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  for batch in train_iterator:\n",
        "      \n",
        "    # zero_grading parameters\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    # model output:  \n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "\n",
        "    # calculate loss:\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    # calculate accuracy:\n",
        "    acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "    # backward:\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    epoch_loss += loss.item()/len(train_iterator)\n",
        "    epoch_acc += acc.item()/len(train_iterator)\n",
        "    \n",
        "  print(f'Epoch: {epoch+1:02} || Train Loss: {epoch_loss:.3f} - Train Acc: {epoch_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "9U29sw7SQd4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the training is complete, we should evaluate the model:"
      ],
      "metadata": {
        "id": "va3BrLU3ZdOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_loss = 0\n",
        "eval_acc = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch in test_iterator:\n",
        "\n",
        "    # model output:\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "\n",
        "    # calculate loss and accuracy:\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = binary_accuracy(predictions, batch.label)\n",
        "    eval_loss += loss.item() / len(test_iterator)\n",
        "    eval_acc += acc.item() / len(test_iterator)\n",
        "\n",
        "print(f'Test Loss: {eval_loss:.3f} - Test Acc: {eval_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "oThHa11tZkmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't be surprised, the results are awful. There are lots of ways to improve what we have done here. Try to see if you can improve things."
      ],
      "metadata": {
        "id": "MPcjj0YxbVo4"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RNN_Sentiment_Analysis.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit ('3.9.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fff836058c255167b80f2d77a2226e7e00ff1ecf6518b7f3cd25e9b70384f747"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}