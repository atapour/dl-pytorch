{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DrpK6lIWrhi"
      },
      "source": [
        "# Deep Learning - AutoEncoder in PyTorch\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide an example that shows the implementation of a simple AutoEncoder in PyTorch.\n",
        "\n",
        "Copyright (c) 2022 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "based on: https://colab.research.google.com/gist/cwkx/e3ef25d0adb6e2f2bf747ce664bab318/conv-autoencoder.ipynb#scrollTo=RGbLY6X-NH4O\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-exrFDujXlUG"
      },
      "source": [
        "We are going to implement an autoencoder. Let's start by importing what we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Xgr3ZNXmQx",
        "outputId": "8451927c-5562-4a2f-9fb4-2a7e708129cb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Device is {device}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jRGkDJEkLqt"
      },
      "source": [
        "Let's set a few variables to make things easier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGWVNAT5kQqy",
        "outputId": "78d14bea-979b-45f2-c2c3-a98d5c5bdd6f"
      },
      "outputs": [],
      "source": [
        "batch_size  = 256\n",
        "n_channels  = 3\n",
        "latent_size = 512\n",
        "print('done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZr-PApBcN4Y"
      },
      "source": [
        "We should now line up the dataset we are going to use. We will be working with the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6AZQ9Kq_1hj"
      },
      "source": [
        "To process the data, we are going to convert the images to 32x32 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbTxY01eY0Aq",
        "outputId": "96dd8182-415f-4b9b-a92e-e25cdeadbee5"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    'data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize((32,32)),\n",
        "        torchvision.transforms.ToTensor()\n",
        "]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, shuffle=True, batch_size=batch_size, drop_last=True\n",
        ")\n",
        "\n",
        "print('\\nThe classes are:')\n",
        "print(*train_dataset.classes, sep = \", \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5UnQLwJZW6O"
      },
      "source": [
        "Now that the dataset is ready, let's look at a few of our images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "tVqAtMBuw8LW",
        "outputId": "55711650-c452-46b2-8b40-7eca0923d806"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_loader.dataset[i][0].permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_dataset.classes[train_loader.dataset[i][1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt8tSeQcy_jZ"
      },
      "source": [
        "We can now create our model, which will be a very simple convolutional network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pou-TRizzZXP",
        "outputId": "d39f2911-f8f4-4e57-b7a2-cd01e33a74c9"
      },
      "outputs": [],
      "source": [
        "# simple block of convolution, batchnorm, and leakyrelu\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_f, out_f):\n",
        "        super(Block, self).__init__()\n",
        "        self.f = nn.Sequential(\n",
        "            nn.Conv2d(in_f, out_f, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_f),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.f(x)\n",
        "\n",
        "# define the model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, f=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encode = nn.Sequential(\n",
        "            Block(n_channels, f),\n",
        "            nn.MaxPool2d(kernel_size=(2,2)), # output = 16x16\n",
        "            Block(f  ,f*2),\n",
        "            nn.MaxPool2d(kernel_size=(2,2)), # output = 8x8\n",
        "            Block(f*2,f*4),\n",
        "            nn.MaxPool2d(kernel_size=(2,2)), # output = 4x4\n",
        "            Block(f*4,f*4),\n",
        "            nn.MaxPool2d(kernel_size=(2,2)), # output = 2x2\n",
        "            Block(f*4,f*4),\n",
        "            nn.MaxPool2d(kernel_size=(2,2)), # output = 1x1\n",
        "            Block(f*4,latent_size),\n",
        "        )\n",
        "\n",
        "        self.decode = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2), # output = 2x2\n",
        "            Block(latent_size,f*4),\n",
        "            nn.Upsample(scale_factor=2), # output = 4x4\n",
        "            Block(f*4,f*4),\n",
        "            nn.Upsample(scale_factor=2), # output = 8x8\n",
        "            Block(f*4,f*2),\n",
        "            nn.Upsample(scale_factor=2), # output = 16x16\n",
        "            Block(f*2,f  ),\n",
        "            nn.Upsample(scale_factor=2), # output = 32x32\n",
        "            nn.Conv2d(f,n_channels, 3,1,1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "A = Autoencoder().to(device)\n",
        "print(f'The model has {len(torch.nn.utils.parameters_to_vector(A.parameters()))} parameters.')\n",
        "\n",
        "print('The optimiser has been created!')\n",
        "optimiser = torch.optim.Adam(A.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBDngw8EueCv"
      },
      "source": [
        "Let's start the main training loop now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ccMuktrKukIj",
        "outputId": "8215e732-de95-4871-8b94-3fd82f7aca7b"
      },
      "outputs": [],
      "source": [
        "epoch = 0\n",
        "# training loop\n",
        "while (epoch < 20):\n",
        "    \n",
        "    # for metrics\n",
        "    loss_arr = np.zeros(0)\n",
        "\n",
        "    # iterate over the training dateset\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        # sample x from the dataset\n",
        "        x, t = batch\n",
        "        x, t = x.to(device), t.to(device)\n",
        "\n",
        "        # do the forward pass with mean squared error\n",
        "        z = A.encode(x)\n",
        "        x_hat = A.decode(z)\n",
        "        # calculate loss:\n",
        "        loss = ((x-x_hat)**2).mean()\n",
        "\n",
        "        # backpropagate to compute the gradients of the loss w.r.t the parameters and optimise\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        # collect stats\n",
        "        loss_arr = np.append(loss_arr, loss.item())\n",
        "\n",
        "    # sample\n",
        "    z = torch.randn_like(z)\n",
        "    g = A.decode(z)\n",
        "\n",
        "    # plot some examples from training\n",
        "    print(\"\\n============================================\")\n",
        "    print(f'Epoch {epoch} Loss: {loss.mean().item()}')\n",
        "    print('Training Examples')\n",
        "    plt.grid(False)\n",
        "    plt.imshow(torchvision.utils.make_grid(x_hat[:16]).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "\n",
        "    # plot results sampled from latent\n",
        "    print('Samples from the Latent Space')\n",
        "    plt.grid(False)\n",
        "    plt.imshow(torchvision.utils.make_grid(g[:16]).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "    print(\"============================================\\n\")\n",
        "\n",
        "    epoch = epoch+1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit ('3.9.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fff836058c255167b80f2d77a2226e7e00ff1ecf6518b7f3cd25e9b70384f747"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
