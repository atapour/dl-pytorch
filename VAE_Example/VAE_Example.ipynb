{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DrpK6lIWrhi"
      },
      "source": [
        "# Deep Learning - Variational Autoencoder (VAE) in PyTorch\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide an example that shows the implementation of a simple Variational Autoencoder (VAE) in PyTorch.\n",
        "\n",
        "Copyright (c) 2022 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-exrFDujXlUG"
      },
      "source": [
        "We are going to implement an autoencoder. Let's start by importing what we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Xgr3ZNXmQx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Device is {device}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZr-PApBcN4Y"
      },
      "source": [
        "We should now line up the dataset we are going to use. We will be working with the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbTxY01eY0Aq"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    'data', train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, shuffle=True, batch_size=256, drop_last=True\n",
        ")\n",
        "\n",
        "print('\\nThe classes are:')\n",
        "print(*train_dataset.classes, sep = \", \")\n",
        "print(f'There are {len(train_dataset)} images in the training set.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5UnQLwJZW6O"
      },
      "source": [
        "Now that the dataset is ready, let's look at a few of our images in our training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVqAtMBuw8LW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_loader.dataset[i][0].clamp(0,1).repeat(3,1,1).permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_dataset.classes[train_loader.dataset[i][1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt8tSeQcy_jZ"
      },
      "source": [
        "We can now create our model, which will be a very simple convolutional network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pou-TRizzZXP"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, n_channels=1, f_dim=32*20*20, z_dim=256):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder layers:\n",
        "        self.enc_conv1 = nn.Conv2d(n_channels, 16, 5)\n",
        "        self.enc_conv2 = nn.Conv2d(16, 32, 5)\n",
        "        # two linear layers with one for the mean and the other the variance\n",
        "        self.enc_linear1 = nn.Linear(f_dim, z_dim)\n",
        "        self.enc_linear2 = nn.Linear(f_dim, z_dim)\n",
        "\n",
        "        # decoder layers:\n",
        "        self.dec_linear = nn.Linear(z_dim, f_dim)\n",
        "        self.dec_conv1 = nn.ConvTranspose2d(32, 16, 5)\n",
        "        self.dec_conv2 = nn.ConvTranspose2d(16, n_channels, 5)\n",
        "\n",
        "    # encoder:\n",
        "    def encoder(self, x):\n",
        "        x = F.relu(self.enc_conv1(x))\n",
        "        x = F.relu(self.enc_conv2(x))\n",
        "        x = x.view(-1, 32*20*20)\n",
        "        # the output is mean (mu) and variance (logVar)\n",
        "        mu = self.enc_linear1(x)\n",
        "        logVar = self.enc_linear2(x)\n",
        "        # mu and logVar are used to sample z and compute KL divergence loss\n",
        "        return mu, logVar\n",
        "\n",
        "    # reparameterisation trick:\n",
        "    def reparameterise(self, mu, logVar):\n",
        "        # from mu and logVar, we can sample via mu + std * eps\n",
        "        std = torch.exp(logVar/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + std * eps\n",
        "\n",
        "    # decoder:\n",
        "    def decoder(self, z):\n",
        "        x = F.relu(self.dec_linear(z))\n",
        "        x = x.view(-1, 32, 20, 20)\n",
        "        x = F.relu(self.dec_conv1(x))\n",
        "        # the output is the same size as the input\n",
        "        x = torch.sigmoid(self.dec_conv2(x))\n",
        "        return x\n",
        "\n",
        "    # forward pass:\n",
        "    def forward(self, x):\n",
        "        mu, logVar = self.encoder(x)\n",
        "        z = self.reparameterise(mu, logVar)\n",
        "        out = self.decoder(z)\n",
        "        # mu and logVar are returned as well as the output for loss computation\n",
        "        return out, mu, logVar\n",
        "\n",
        "model = VAE().to(device)\n",
        "print(f'The model has {len(torch.nn.utils.parameters_to_vector(model.parameters()))} parameters.')\n",
        "\n",
        "print('The optimiser has been created!')\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBDngw8EueCv"
      },
      "source": [
        "Let's start the main training loop now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccMuktrKukIj"
      },
      "outputs": [],
      "source": [
        "epoch = 0\n",
        "# training loop\n",
        "while (epoch < 20):\n",
        "    \n",
        "    # for metrics\n",
        "    loss_arr = np.zeros(0)\n",
        "\n",
        "    # iterate over the training dateset\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        # sample x from the dataset\n",
        "        x, _ = batch\n",
        "        x = x.to(device)\n",
        "\n",
        "        # forward pass to obtain image, mu, and logVar\n",
        "        x_hat, mu, logVar = model(x)\n",
        "\n",
        "        # caculate loss - BCE combined with KL\n",
        "        kl_divergence = 0.5 * torch.sum(-1 - logVar + mu.pow(2) + logVar.exp())\n",
        "        loss = F.binary_cross_entropy(x_hat, x, size_average=False) + kl_divergence\n",
        "\n",
        "        # backpropagate to compute the gradients of the loss w.r.t the parameters and optimise\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        # collect stats\n",
        "        loss_arr = np.append(loss_arr, loss.item())\n",
        "\n",
        "    # sample\n",
        "    z = torch.randn_like(mu)\n",
        "    g = model.decoder(z)\n",
        "\n",
        "    # plot some examples from training\n",
        "    print(\"\\n============================================\")\n",
        "    print(f'Epoch {epoch} Loss: {loss.mean().item()}')\n",
        "    print('Training Examples')\n",
        "    plt.grid(False)\n",
        "    plt.imshow(torchvision.utils.make_grid(x_hat[:16]).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "\n",
        "    # plot results sampled from latent\n",
        "    print('Samples from the Latent Space')\n",
        "    plt.grid(False)\n",
        "    plt.imshow(torchvision.utils.make_grid(g[:16]).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "    print(\"============================================\\n\")\n",
        "\n",
        "    epoch += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit ('3.9.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fff836058c255167b80f2d77a2226e7e00ff1ecf6518b7f3cd25e9b70384f747"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
