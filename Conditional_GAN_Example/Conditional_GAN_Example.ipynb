{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DrpK6lIWrhi"
      },
      "source": [
        "# Deep Learning - Conditional GAN in PyTorch\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide an example that shows the implementation of a Conditional Generative Adversarial Network in PyTorch.\n",
        "\n",
        "Copyright (c) 2022 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-exrFDujXlUG"
      },
      "source": [
        "We are going to implement a Conditional GAN. Let's start by importing what we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Xgr3ZNXmQx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f\"Device is {device}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZr-PApBcN4Y"
      },
      "source": [
        "We should now line up the dataset we are going to use. We will be working with the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6AZQ9Kq_1hj"
      },
      "source": [
        "To process the data, we are going to convert the images to 32x32 images to make the work easier for demonstration purposes.\n",
        "\n",
        "Since our dataset has ten classes with labels, we are going to use the labels as the auxiliary data for our conditional GAN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbTxY01eY0Aq"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize([32,32]),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])),\n",
        "shuffle=True, batch_size=64, drop_last=True)\n",
        "\n",
        "print(f\"Dataloader created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5UnQLwJZW6O"
      },
      "source": [
        "Our dataset is tiny and is not really suited for any real applications, but it will demonstrate the process. Let's look at a few of our images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVqAtMBuw8LW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_loader.dataset[i][0].clamp(0,1).repeat(3,1,1).permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt8tSeQcy_jZ"
      },
      "source": [
        "We can now create our models, we need a Generator and a Discriminator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pou-TRizzZXP"
      },
      "outputs": [],
      "source": [
        "# A few parameters:\n",
        "n_channels = 1\n",
        "img_width = 32\n",
        "\n",
        "# define the generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_size=100, label_size=10):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(latent_size+label_size, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, n_channels*img_width*img_width),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, c):\n",
        "        x, c = x.view(x.size(0), -1), c.view(c.size(0), -1).float()\n",
        "        x = torch.cat((x, c), 1) # [input, label] concatenated\n",
        "        x = self.layer(x)\n",
        "        return x.view(x.size(0), n_channels, img_width, img_width)\n",
        "\n",
        "# define the discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, label_size=10):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(n_channels*img_width*img_width+label_size, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, c):        \n",
        "        x, c = x.view(x.size(0), -1), c.view(c.size(0), -1).float()\n",
        "        x = torch.cat((x, c), 1) # [input, label] concatenated\n",
        "        return self.layer(x)\n",
        "        \n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "print(f'Generator has {len(torch.nn.utils.parameters_to_vector(G.parameters()))} parameters.')\n",
        "print(f'Discriminator has {len(torch.nn.utils.parameters_to_vector(D.parameters()))} parameters')\n",
        "\n",
        "# initialise the optimiser\n",
        "optimiser_G = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimiser_D = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "print('Optimisers have been created!')\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "print('Loss function is Binary Cross Entropy!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBDngw8EueCv"
      },
      "source": [
        "Let's start the main training loop now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccMuktrKukIj"
      },
      "outputs": [],
      "source": [
        "epoch = 0\n",
        "# training loop\n",
        "while (epoch<20000):\n",
        "    \n",
        "    # arrays for metrics\n",
        "    logs = {}\n",
        "    gen_loss_arr = np.zeros(0)\n",
        "    dis_loss_arr = np.zeros(0)\n",
        "\n",
        "    # iterate over the train dateset\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        x, t = batch\n",
        "        x, t = x.to(device), t.to(device)\n",
        "\n",
        "        # convert target labels \"t\" to a one-hot vector, e.g. 3 becomes [0,0,0,1,0,0,0,...]\n",
        "        y = torch.zeros(x.size(0), 10).long().to(device).scatter(1, t.view(x.size(0),1), 1)\n",
        "\n",
        "        # train discriminator\n",
        "        z = torch.randn(x.size(0), 100).to(device)\n",
        "        l_r = criterion(D(x,y),       torch.ones([64,1]).to(device)) # real -> 1\n",
        "        l_f = criterion(D(G(z,y),y), torch.zeros([64,1]).to(device)) # fake -> 0\n",
        "        loss_d = (l_r + l_f)/2.0\n",
        "        optimiser_D.zero_grad()\n",
        "        loss_d.backward()\n",
        "        optimiser_D.step()\n",
        "        \n",
        "        # train generator\n",
        "        z = torch.randn(x.size(0), 100).to(device)\n",
        "        loss_g = criterion(D(G(z,y),y), torch.ones([64,1]).to(device)) # fake -> 1\n",
        "        optimiser_G.zero_grad()\n",
        "        loss_g.backward()\n",
        "        optimiser_G.step()\n",
        "\n",
        "        gen_loss_arr = np.append(gen_loss_arr, loss_g.item())\n",
        "        dis_loss_arr = np.append(dis_loss_arr, loss_d.item())\n",
        "\n",
        "\n",
        "    # conditional sample of 10x10\n",
        "    G.eval()\n",
        "    print('loss d: {:.3f}, loss g: {:.3f}'.format(gen_loss_arr.mean(), dis_loss_arr.mean()))\n",
        "    grid = np.zeros([img_width*10, img_width*10])\n",
        "    for j in range(10):\n",
        "        c = torch.zeros([10, 10]).to(device)\n",
        "        c[:, j] = 1\n",
        "        z = torch.randn(10, 100).to(device)\n",
        "        y_hat = G(z,c).view(10, img_width, img_width)\n",
        "        result = y_hat.cpu().data.numpy()\n",
        "        grid[j*img_width:(j+1)*img_width] = np.concatenate([x for x in result], axis=-1)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(grid, cmap='gray')\n",
        "    plt.show()\n",
        "    plt.pause(0.0001)\n",
        "    G.train()\n",
        "\n",
        "    epoch = epoch+1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Conditional_GAN_Example.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit ('3.9.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fff836058c255167b80f2d77a2226e7e00ff1ecf6518b7f3cd25e9b70384f747"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
