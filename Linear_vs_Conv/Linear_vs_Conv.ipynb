{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_vs_Conv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N22Uz-kLiZW"
      },
      "source": [
        "# Deep Learning - Simple Linear and Convolutional Examples in PyTorch\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide an example that shows the implementation of a simple linear as well as a convolutional network in PyTorch.\n",
        "\n",
        "Copyright (c) 2024 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to implement a couple of simple networks. Let's start by importing what we need:"
      ],
      "metadata": {
        "id": "BvVvYxBainyM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK1Jl7nkLnPA"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run1dh_hM0oO"
      },
      "source": [
        "Let's import the dataset first. We will use the FashionMNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK383zeDM4Ac"
      },
      "source": [
        "# helper function to make getting another batch of data easier\n",
        "def cycle(iterable):\n",
        "    while True:\n",
        "        for x in iterable:\n",
        "            yield x\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.FashionMNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(32),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])),\n",
        "batch_size=64, drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.FashionMNIST('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(32),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])),\n",
        "batch_size=64, drop_last=True)\n",
        "\n",
        "train_iterator = iter(cycle(train_loader))\n",
        "test_iterator = iter(cycle(test_loader))\n",
        "\n",
        "print(f'Size of training dataset: {len(train_loader.dataset)}')\n",
        "print(f'Size of test dataset: {len(test_loader.dataset)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-FdW5HnimG2"
      },
      "source": [
        "Here, we will view some of the test dataset images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtJs-qxHRLXz"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_loader.dataset[i][0][0], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[test_loader.dataset[i][1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnjh12UbNFpV"
      },
      "source": [
        "Now, let's define a simple linear model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGbLY6X-NH4O"
      },
      "source": [
        "# define the model\n",
        "class LinearNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearNetwork, self).__init__()\n",
        "        layers = nn.ModuleList()\n",
        "        layers.append(nn.Linear(in_features=1024, out_features=512))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Linear(in_features=512, out_features=10))\n",
        "        self.layers = layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        for m in self.layers:\n",
        "            x = m(x)\n",
        "        return x\n",
        "\n",
        "N = LinearNetwork().to(device)\n",
        "\n",
        "print(f'Number of model parameters is: {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
        "\n",
        "# initialise the optimiser\n",
        "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
        "epoch = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1UBl0PJjY-f"
      },
      "source": [
        "**Main training and testing loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb5909Y8D_zx"
      },
      "source": [
        "while (epoch<5):\n",
        "\n",
        "    # arrays for metrics\n",
        "    logs = {}\n",
        "    train_loss_arr = np.zeros(0)\n",
        "    train_acc_arr = np.zeros(0)\n",
        "    test_acc_arr = np.zeros(0)\n",
        "\n",
        "    # iterate over some of the train dateset\n",
        "    for i in range(1000):\n",
        "        x,t = next(train_iterator)\n",
        "        x,t = x.to(device), t.to(device)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        p = N(x.view(x.size(0), -1))\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        loss = torch.nn.functional.cross_entropy(p, t)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
        "        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "    # iterate entire test dataset\n",
        "    for x,t in test_loader:\n",
        "        x,t = x.to(device), t.to(device)\n",
        "        p = N(x.view(x.size(0), -1))\n",
        "        loss = torch.nn.functional.cross_entropy(p, t)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "    print('train loss: {:.3f}, train acc: {:.3f}, test acc: {:.3f}'.format(\n",
        "        train_loss_arr.mean(),train_acc_arr.mean(),test_acc_arr.mean()))\n",
        "\n",
        "    epoch = epoch+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTFqiEHzMOVw"
      },
      "source": [
        "Now, let's create a simple convolutional model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "class ConvNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetwork, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
        "        self.fc = nn.Conv2d(in_channels=128, out_channels=10, kernel_size=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.fc(x)\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "# create the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "N = ConvNetwork().to(device)\n",
        "\n",
        "# print the number of model parameters\n",
        "print(f'Number of model parameters is: {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
        "\n",
        "# initialise the optimiser\n",
        "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
        "epoch = 0"
      ],
      "metadata": {
        "id": "YhMlwQZCkTWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main training and testing loop**"
      ],
      "metadata": {
        "id": "WbONWR_4lLqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while (epoch<5):\n",
        "\n",
        "    # arrays for metrics\n",
        "    logs = {}\n",
        "    train_loss_arr = np.zeros(0)\n",
        "    train_acc_arr = np.zeros(0)\n",
        "    test_acc_arr = np.zeros(0)\n",
        "\n",
        "    # iterate over some of the train dateset\n",
        "    for i in range(1000):\n",
        "        x,t = next(train_iterator)\n",
        "        x,t = x.to(device), t.to(device)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        p = N(x)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        loss = torch.nn.functional.cross_entropy(p, t)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
        "        train_acc_arr = np.append(train_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "    # iterate entire test dataset\n",
        "    for x,t in test_loader:\n",
        "        x,t = x.to(device), t.to(device)\n",
        "        p = N(x)\n",
        "        loss = torch.nn.functional.cross_entropy(p, t)\n",
        "        pred = p.argmax(dim=1, keepdim=True)\n",
        "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(t.view_as(pred)).float().mean().item())\n",
        "\n",
        "    print('train loss: {:.3f}, train acc: {:.3f}, test acc: {:.3f}'.format(\n",
        "        train_loss_arr.mean(),train_acc_arr.mean(),test_acc_arr.mean()))\n",
        "\n",
        "    epoch = epoch+1"
      ],
      "metadata": {
        "id": "afbyUF9ulOhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}