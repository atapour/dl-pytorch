{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DrpK6lIWrhi"
      },
      "source": [
        "# PyTorch Programming - Demonstrating A Simple Classifier\n",
        "---\n",
        "\n",
        "## Author : Amir Atapour-Abarghouei, amir.atapour-abarghouei@durham.ac.uk\n",
        "\n",
        "This notebook will provide an example that shows the use of a simple neural network for classification in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-exrFDujXlUG"
      },
      "source": [
        "Let's start by importing what we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7Xgr3ZNXmQx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "print('done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSQ3i5xmo1lY"
      },
      "source": [
        "Since we are going to be training a model, we want to make sure that we are using a GPU to accelerate our training. If you are using Google Colab, you should:\n",
        "\n",
        "Select Runtime -> Change runtime type -> GPU\n",
        "\n",
        "If you are running this code on a local machine that has GPU hardware, you can just run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfzITvMDo5-4"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')\n",
        "print(f'Device type is {device}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZr-PApBcN4Y"
      },
      "source": [
        "We are going to use the [livelossplot](https://github.com/stared/livelossplot) library to help us plot our loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bGhK9wmXsA_"
      },
      "outputs": [],
      "source": [
        "!pip install livelossplot --quiet\n",
        "\n",
        "from livelossplot import PlotLosses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5UnQLwJZW6O"
      },
      "source": [
        "Here, we're going to define a helper function to make getting another batch of data easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVqAtMBuw8LW"
      },
      "outputs": [],
      "source": [
        "def cycle(iterable):\n",
        "  while True:\n",
        "    for x in iterable:\n",
        "      yield x\n",
        "\n",
        "print('done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt8tSeQcy_jZ"
      },
      "source": [
        "For this example, we are going to be using the [FashionMNIST](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html) dataset. [This dataset](https://github.com/zalandoresearch/fashion-mnist) consists of 60,000 images of items of clothing with the same resolution as the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset.\n",
        "\n",
        "In the following, these are the categories of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pou-TRizzZXP"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "print(\"The classes are:\", *class_names, sep = \", \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBDngw8EueCv"
      },
      "source": [
        "Let's load the data for the training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccMuktrKukIj"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.FashionMNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(32),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])),\n",
        "shuffle=True, batch_size=256, drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.FashionMNIST('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(32),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])),\n",
        "batch_size=512, drop_last=True)\n",
        "\n",
        "train_iterator = iter(cycle(train_loader))\n",
        "test_iterator = iter(cycle(test_loader))\n",
        "\n",
        "print(f'Size of training set: {len(train_loader.dataset)}')\n",
        "print(f'Size of test set: {len(test_loader.dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Z8dpZ2I8pY"
      },
      "source": [
        "We can have a look at some of the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqvDIMfvI_Mq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x, y = next(train_iterator)\n",
        "\n",
        "grid = torchvision.utils.make_grid(x[:16])\n",
        "grid = (grid-grid.min())/(grid.max()-grid.min())\n",
        "\n",
        "plt.imshow(grid.permute(1, 2, 0))\n",
        "\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C9DA2V1AtmJ"
      },
      "source": [
        "Now that the data is ready to go, let's create a simple neural network. Our network consists of a linear layer with a [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) activation function followed by a second linear layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51-x09MOumTl"
      },
      "outputs": [],
      "source": [
        "class SimpleNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNetwork, self).__init__()\n",
        "        self.l1 = nn.Linear(in_features=1024, out_features=512)\n",
        "        self.l2 = nn.Linear(in_features=512, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.l2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25GE0Jbxu-ak"
      },
      "source": [
        "Our neural network should have its weights with the `requires_grad` already set and on the device we want it to be, whether it be CPU or GPU. Let's look at the weights of the first layer: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJUN6bRALZGL"
      },
      "outputs": [],
      "source": [
        "print(model.l1.weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCWZ8Lf24i0"
      },
      "source": [
        "While we can manually adjust the parameters by running an optimisation algorithm like Stochastic Gradient Descent, PyTorch offers a variety of [optimisers](https://pytorch.org/docs/stable/optim.html#algorithms) that can help train our neural networks easily.\n",
        "\n",
        "Here, we will use [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) [from [this paper](https://arxiv.org/abs/1412.6980)], which takes advantage of momentum by using moving average of the gradients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpxus8583aX6"
      },
      "outputs": [],
      "source": [
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(optimiser)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl_Qi0moiajE"
      },
      "source": [
        "A few things to set up now before getting to the main loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkcwOfhbie2E"
      },
      "outputs": [],
      "source": [
        "# initialising step variable\n",
        "step = 0\n",
        "\n",
        "# defining the loss function\n",
        "# refer to https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# to plot losses\n",
        "liveloss = PlotLosses()\n",
        "\n",
        "# to keep the logs for loss plots\n",
        "logs = {}\n",
        "\n",
        "print('done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyiYpF-44lw4"
      },
      "source": [
        "Now, we get to the main loop.\n",
        "\n",
        "How much you train your model is often dependent on how much data you have, how representative of the real world your training data is and model capacity. We are going to train the network for *5,000 steps*.\n",
        "\n",
        "Every 50 steps, we are going to evaluate the model and log the training and testing loss and accuracy. We will use [livelossplot](https://pypi.org/project/livelossplot/0.1.2/) to plot losses in the notebook, but you can use a variety of packages to do the same.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKGRvBn85m0K"
      },
      "outputs": [],
      "source": [
        "# outer loop - going over the steps we want to train for\n",
        "while step < 5000:\n",
        "  # inner loop - iterating over the batches\n",
        "  for i, batch in enumerate(train_loader):\n",
        "\n",
        "    # getting the input and the ground truth labels from the training set\n",
        "    x, gt = batch\n",
        "    x, gt = x.to(device), gt.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    x = x.view(x.size(0), -1)\n",
        "    output = model(x)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(output, gt)\n",
        "\n",
        "    # explicitly set the gradients to zero before backpropagation\n",
        "    model.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "    step += 1\n",
        "\n",
        "    # calculating the accuracy\n",
        "    _, argmax = torch.max(output, dim=1)\n",
        "    accuracy = argmax.eq(gt).float().mean() * 100\n",
        "\n",
        "    # every 50 steps we evaluate the model on the test set\n",
        "    if step % 50 == 0:\n",
        "\n",
        "      # when we test, we don't need gradients\n",
        "      with torch.no_grad():\n",
        "\n",
        "        # beginning the loop for evaluation:\n",
        "        for j, test_batch in enumerate(test_loader):\n",
        "\n",
        "          # getting the input and the ground truth labels from the training set\n",
        "          x, gt = test_batch\n",
        "          x, gt = x.to(device), gt.to(device)\n",
        "\n",
        "          # forward pass\n",
        "          x = x.view(x.size(0), -1)\n",
        "          output = model(x)\n",
        "\n",
        "          # test loss\n",
        "          test_loss = criterion(output, gt)\n",
        "\n",
        "          # calculating the test accuracy\n",
        "          _, argmax = torch.max(output, dim=1)\n",
        "          test_accuracy = argmax.eq(gt).float().mean() * 100\n",
        "\n",
        "        # logging train and test losses and accuracies\n",
        "        logs['Loss'] = loss.item()\n",
        "        logs['val_Loss'] = test_loss.item()\n",
        "        logs['Accuracy'] = accuracy.item()\n",
        "        logs['val_Accuracy'] = test_accuracy.item()\n",
        "        liveloss.update(logs)\n",
        "        liveloss.send()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nice! :+1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-------------------\n",
        "\n",
        "Copyright (c) 2023 Amir Atapour-Abarghouei, UK.\n",
        "\n",
        "based on https://github.com/cwkx/ml-materials\n",
        "\n",
        "License : LGPL - http://www.gnu.org/licenses/lgpl.html"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "4.PyTorch_Programming_Classifier.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit ('3.9.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fff836058c255167b80f2d77a2226e7e00ff1ecf6518b7f3cd25e9b70384f747"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
